{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218ba182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configargparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from models.models import KKTNetMLP, GNNPolicy\n",
    "from data.datasets import LPDataset, GraphDataset, pad_collate_graphs, make_pad_collate\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90d4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = configargparse.ArgumentParser(\n",
    "        allow_abbrev=False,\n",
    "        description=\"evaluate a trained model and plot predictions\",\n",
    "        default_config_files=[\"config.yml\"],\n",
    "    )\n",
    "\n",
    "t = parser.add_argument_group(\"testing\")\n",
    "t.add_argument(\n",
    "    \"--ckpt\", required=True, help=\"Path to best.pt or dir containing it.\"\n",
    ")\n",
    "t.add_argument(\"--split\", choices=[\"test\", \"val\"], default=\"test\")\n",
    "t.add_argument(\"--out_dir\", type=str, default=\"outputs/eval-embeddings\")\n",
    "t.add_argument(\n",
    "    \"--device\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    help=\"CUDA device like '0' or 'cpu' (default: from ckpt args/devices).\",\n",
    ")\n",
    "\n",
    "t.add_argument(\"--file_path\", type=str, required=True, help=\"Path to single .bg file\")\n",
    "\n",
    "tr = parser.add_argument_group(\"training\")\n",
    "tr.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "tr.add_argument(\"--use_bipartite_graphs\", action=\"store_true\")\n",
    "\n",
    "GNNPolicy.add_args(parser)\n",
    "\n",
    "args, _ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6b290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(ckpt='exps/kkt_20251021_090044/best.pt', split='test', out_dir='outputs', device='0', file_path='data/instances/RND/instance/test/2/RND-2-0012.lp', lr=0.001, use_bipartite_graphs=False, embedding_size=128, cons_nfeats=4, edge_nfeats=1, var_nfeats=18, num_emb_type='periodic', num_emb_bins=32, num_emb_freqs=16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0bfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dir = Path(args.out_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd19f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(str(args.ckpt), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77513207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original problem has 2 variables (0 bin, 0 int, 0 impl, 2 cont) and 2 constraints\n"
     ]
    }
   ],
   "source": [
    "use_bipartite_graphs = args.use_bipartite_graphs\n",
    "problems = [\"RND\"]\n",
    "files = [args.file_path]\n",
    "\n",
    "dataset = GraphDataset(files) if use_bipartite_graphs else LPDataset(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67637a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.use_bipartite_graphs:\n",
    "    m,n = dataset.shapes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c288a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 189,\n",
       " 'model': OrderedDict([('net.0.weight',\n",
       "               tensor([[ 0.2921,  0.2666, -0.1132,  ...,  0.0313, -0.1886,  0.2727],\n",
       "                       [ 0.3560, -0.3060,  0.3288,  ...,  0.1476,  0.1360,  0.0152],\n",
       "                       [ 0.2938, -0.0162, -0.1531,  ..., -0.0897, -0.1494,  0.2415],\n",
       "                       ...,\n",
       "                       [ 0.0856, -0.0019, -0.3015,  ...,  0.0244,  0.3176,  0.2198],\n",
       "                       [-0.1736, -0.1370, -0.1221,  ..., -0.3502,  0.1231,  0.2690],\n",
       "                       [-0.0136, -0.2379, -0.2337,  ...,  0.0410,  0.0512,  0.4480]])),\n",
       "              ('net.0.bias',\n",
       "               tensor([ 0.1389,  0.0501, -0.0379,  0.1714,  0.1032, -0.3229, -0.2526,  0.0268,\n",
       "                        0.1345,  0.1983, -0.2454, -0.3713, -0.0146, -0.0427,  0.0928, -0.0282,\n",
       "                        0.2308,  0.0806,  0.1941, -0.2267,  0.0691,  0.0897, -0.2069,  0.1272,\n",
       "                       -0.3195,  0.2527,  0.0558,  0.0275,  0.1401,  0.0078,  0.1144,  0.1941,\n",
       "                       -0.2757,  0.2021, -0.0049, -0.0497,  0.0514,  0.2232, -0.1856, -0.2468,\n",
       "                        0.1919, -0.0459,  0.0936,  0.0227,  0.0988,  0.2372, -0.1904, -0.1794,\n",
       "                        0.1424, -0.0104, -0.0227, -0.3382,  0.2384, -0.0044, -0.0703, -0.1174,\n",
       "                       -0.0692,  0.1501, -0.0013,  0.2354,  0.0126, -0.0224,  0.1592,  0.0451,\n",
       "                       -0.0521,  0.1258,  0.2930,  0.0475,  0.2230,  0.1763,  0.1224,  0.1310,\n",
       "                        0.0994,  0.0553,  0.2694,  0.3138,  0.1223,  0.0333,  0.2896, -0.3536,\n",
       "                        0.2201,  0.1693,  0.1892, -0.0131, -0.2781,  0.2027, -0.1592,  0.0681,\n",
       "                        0.1984, -0.3380,  0.0432, -0.0626,  0.2199, -0.2369,  0.1907,  0.1978,\n",
       "                        0.1555,  0.2708,  0.0773, -0.4589,  0.1929,  0.0055,  0.0284, -0.3432,\n",
       "                       -0.0260, -0.1028,  0.3421,  0.1877,  0.1962,  0.1874, -0.2445, -0.1386,\n",
       "                       -0.0993, -0.1570,  0.2270,  0.1187,  0.2730, -0.0191, -0.3188, -0.1067,\n",
       "                        0.1952,  0.2074,  0.0795, -0.0342, -0.3383, -0.2175,  0.1372, -0.1312,\n",
       "                        0.1398,  0.0450, -0.1731,  0.2009, -0.1595,  0.0324, -0.0902, -0.4273,\n",
       "                        0.0673,  0.0700, -0.2101,  0.1975, -0.3107, -0.4306, -0.2552, -0.0929,\n",
       "                       -0.0549, -0.0152,  0.1470, -0.4016,  0.0550,  0.0444,  0.0716,  0.3347,\n",
       "                        0.1688, -0.2175, -0.3150, -0.0191, -0.2038,  0.0915,  0.0227,  0.2719,\n",
       "                        0.1254, -0.0617, -0.0568,  0.0710, -0.0082,  0.2647, -0.2964,  0.1102,\n",
       "                       -0.2212, -0.2984, -0.0379,  0.1253,  0.2175,  0.0604,  0.0216, -0.0128,\n",
       "                       -0.1169,  0.0371,  0.0409,  0.2379,  0.1967, -0.2691,  0.0176, -0.1755,\n",
       "                       -0.0272, -0.3329,  0.0960, -0.1444,  0.3056,  0.2381, -0.2427, -0.3084,\n",
       "                        0.0282, -0.0892,  0.0902, -0.2113,  0.1212, -0.3214, -0.1887, -0.2308,\n",
       "                        0.1661,  0.0033, -0.3357, -0.1903, -0.1551, -0.3737,  0.0468,  0.1383,\n",
       "                       -0.0428, -0.0948,  0.0647, -0.2255, -0.2238,  0.0178,  0.2358, -0.0667,\n",
       "                        0.1572, -0.1023, -0.0752, -0.3612,  0.2302,  0.3118,  0.0326,  0.1533,\n",
       "                        0.2256,  0.1253,  0.1777, -0.3852, -0.3136, -0.2487,  0.1041, -0.3136,\n",
       "                       -0.2318, -0.0865, -0.3528,  0.0019,  0.0684, -0.2774,  0.2339, -0.1637,\n",
       "                       -0.0253,  0.2586,  0.2804, -0.0518, -0.2871, -0.1731,  0.0439,  0.1755,\n",
       "                        0.1382, -0.1703, -0.3316, -0.3089, -0.0630, -0.0146, -0.2115, -0.2686])),\n",
       "              ('net.2.weight',\n",
       "               tensor([[ 0.0107, -0.0126, -0.0592,  ...,  0.0066, -0.0019,  0.0021],\n",
       "                       [ 0.0082, -0.0023,  0.0530,  ...,  0.0227, -0.0246, -0.0438],\n",
       "                       [-0.0050, -0.0388, -0.0318,  ..., -0.0527, -0.0753,  0.0192],\n",
       "                       ...,\n",
       "                       [ 0.0180,  0.0097,  0.0188,  ..., -0.0132, -0.0492, -0.0585],\n",
       "                       [ 0.0132,  0.0128,  0.0314,  ..., -0.0085, -0.0288,  0.0512],\n",
       "                       [ 0.0114,  0.0713,  0.0156,  ..., -0.0264, -0.1261, -0.0084]])),\n",
       "              ('net.2.bias',\n",
       "               tensor([-0.0166,  0.0470,  0.0229, -0.0522,  0.0471,  0.0473, -0.0414,  0.0340,\n",
       "                        0.0427,  0.0152,  0.0572, -0.0128, -0.0150,  0.0374,  0.0322, -0.0645,\n",
       "                       -0.0828, -0.0461,  0.0411,  0.0174, -0.0327,  0.0075,  0.0083,  0.0227,\n",
       "                       -0.0207,  0.0367, -0.0369,  0.0311,  0.0130,  0.0235, -0.0629, -0.0233,\n",
       "                        0.0468, -0.0498,  0.0575, -0.0366, -0.0603,  0.0068,  0.0271, -0.0139,\n",
       "                       -0.0204,  0.0473,  0.0444,  0.0007,  0.0088,  0.0631,  0.0332, -0.0251,\n",
       "                       -0.0565, -0.0516,  0.0206, -0.0271, -0.0008, -0.0073, -0.0448,  0.0308,\n",
       "                        0.0332,  0.0215, -0.0545, -0.0416,  0.0384, -0.0696,  0.0511,  0.0492,\n",
       "                       -0.0144,  0.0498,  0.0241,  0.0082,  0.0007, -0.0225, -0.0126,  0.0520,\n",
       "                       -0.1059, -0.0292, -0.0071, -0.0229, -0.0526, -0.0340,  0.0268, -0.0426,\n",
       "                        0.0202, -0.0185, -0.0254,  0.0495,  0.0426, -0.0188,  0.0268,  0.0481,\n",
       "                       -0.0455,  0.0006, -0.0018, -0.0197,  0.0212,  0.0109,  0.0554, -0.0137,\n",
       "                       -0.0433,  0.0537,  0.0269,  0.0041,  0.0709, -0.0336, -0.0226,  0.0555,\n",
       "                        0.0572,  0.0365,  0.0311, -0.0249,  0.0521, -0.0796,  0.0116,  0.0387,\n",
       "                       -0.0186,  0.0286, -0.0058,  0.0140, -0.0538, -0.0011,  0.0180,  0.0337,\n",
       "                       -0.0139, -0.0052, -0.0809,  0.0313,  0.0266, -0.0389,  0.0469, -0.0067,\n",
       "                        0.0248,  0.0282,  0.0224, -0.0141, -0.0337,  0.0504, -0.0005,  0.0596,\n",
       "                        0.0087, -0.0247, -0.0118, -0.0578,  0.0151,  0.0421,  0.0166, -0.0757,\n",
       "                       -0.0105, -0.0209,  0.0732,  0.0129, -0.0505, -0.0546,  0.0180, -0.0777,\n",
       "                       -0.0267,  0.0187, -0.0357, -0.0642,  0.0329,  0.0696,  0.0382, -0.0115,\n",
       "                        0.0123,  0.0643, -0.0017,  0.0812,  0.0018,  0.0517, -0.0745,  0.0227,\n",
       "                       -0.0484, -0.0571, -0.0455,  0.0064, -0.0066, -0.0398,  0.0553, -0.0335,\n",
       "                        0.0056,  0.0369,  0.0290, -0.0694,  0.0379,  0.0182, -0.0242, -0.0392,\n",
       "                        0.0210,  0.0106, -0.0789, -0.0580,  0.0353,  0.0029,  0.0178,  0.0229,\n",
       "                       -0.0140, -0.0423,  0.0561,  0.0559, -0.0573, -0.0020,  0.0125, -0.0476,\n",
       "                        0.0224, -0.0432, -0.0852, -0.0107,  0.0371,  0.0182, -0.0487,  0.0336,\n",
       "                       -0.0983, -0.0629, -0.0216,  0.0021,  0.0278,  0.0315, -0.0830,  0.0283,\n",
       "                        0.0276, -0.0680, -0.0413,  0.0601,  0.0330, -0.0628, -0.0486,  0.0284,\n",
       "                       -0.0003,  0.0097, -0.0020, -0.0296,  0.0514, -0.0480, -0.0289,  0.0472,\n",
       "                        0.0128, -0.0615, -0.0768,  0.0226, -0.0788, -0.0245,  0.0428,  0.0663,\n",
       "                       -0.0179,  0.0007,  0.0241,  0.0472,  0.0135,  0.0547, -0.0582, -0.0274,\n",
       "                        0.0686, -0.0398, -0.0340,  0.0002, -0.0276, -0.0365,  0.0449,  0.0572])),\n",
       "              ('net.4.weight',\n",
       "               tensor([[ 0.0625,  0.0141, -0.1431,  ...,  0.0610, -0.0242,  0.0449],\n",
       "                       [ 0.0285, -0.0506, -0.0233,  ..., -0.1003,  0.0137,  0.0671],\n",
       "                       [ 0.0147, -0.0436, -0.0408,  ..., -0.0532, -0.0340,  0.0715],\n",
       "                       ...,\n",
       "                       [-0.0521, -0.0131,  0.0346,  ...,  0.0529,  0.0050, -0.0912],\n",
       "                       [ 0.0032, -0.0053, -0.0285,  ..., -0.0628, -0.0124,  0.0566],\n",
       "                       [-0.0081, -0.0165, -0.0052,  ...,  0.0407,  0.0172, -0.0626]])),\n",
       "              ('net.4.bias',\n",
       "               tensor([ 1.4250e-02, -5.9641e-02,  5.6666e-02,  4.3735e-02,  1.5685e-02,\n",
       "                       -3.2779e-02, -8.5122e-02, -2.9659e-02,  8.5341e-02,  1.5105e-03,\n",
       "                       -3.0567e-02,  1.4883e-02,  3.4241e-02, -6.2276e-02,  4.7915e-02,\n",
       "                       -2.3461e-02, -4.6991e-02, -3.7876e-02, -6.4674e-02, -5.1949e-02,\n",
       "                        2.1420e-02, -4.5940e-02,  7.7615e-03,  3.5800e-02, -1.3122e-02,\n",
       "                        4.6856e-02,  4.9494e-02, -5.0332e-02, -5.6256e-02,  1.8618e-02,\n",
       "                        5.7786e-02, -5.7701e-02,  7.5036e-02,  2.0017e-02,  3.6336e-02,\n",
       "                       -2.6683e-02,  3.7812e-02, -4.0346e-02, -1.1921e-02,  3.9703e-03,\n",
       "                        7.0962e-03,  5.3422e-02, -3.8254e-02,  4.4904e-03,  2.9357e-02,\n",
       "                        9.8605e-06, -1.2006e-01, -7.8728e-03, -1.9720e-02, -6.6964e-02,\n",
       "                       -2.7737e-02, -3.0742e-02,  5.2986e-02, -5.1113e-02, -5.9275e-03,\n",
       "                        6.9259e-03, -3.0216e-02,  1.0658e-02, -9.6852e-03,  3.9698e-03,\n",
       "                       -1.2466e-03,  4.8473e-02, -1.0821e-02,  6.2182e-02,  4.7270e-02,\n",
       "                       -5.0448e-02, -4.4063e-02,  3.9064e-02,  1.8124e-02,  3.1313e-02,\n",
       "                       -6.3756e-02,  2.3472e-02, -8.0575e-02,  4.2855e-02,  2.1861e-02,\n",
       "                        3.9984e-02,  3.2525e-02,  7.1454e-03, -4.9265e-02,  2.4183e-02,\n",
       "                        4.3334e-02, -1.5623e-02, -8.2108e-02,  2.6819e-03, -1.2606e-02,\n",
       "                       -6.5053e-03, -3.5258e-02, -5.1808e-02, -3.1785e-02, -2.4614e-02,\n",
       "                       -6.5160e-02,  4.8543e-02,  1.2341e-02, -5.8751e-02,  1.0567e-01,\n",
       "                        6.7405e-02,  5.5599e-02,  7.8579e-02,  2.1994e-02,  8.6567e-02,\n",
       "                       -8.9229e-02,  4.0150e-02, -5.8525e-03, -1.6100e-02, -2.9494e-02,\n",
       "                       -2.2507e-02, -2.2677e-02, -9.1641e-04,  6.2086e-02, -3.6143e-02,\n",
       "                       -6.5259e-02, -5.6792e-02, -4.9827e-02, -1.0270e-01,  6.8918e-03,\n",
       "                        3.9371e-02,  2.2854e-02, -9.6164e-03, -1.5649e-02,  1.3502e-02,\n",
       "                       -3.4184e-02, -3.3070e-02,  4.1241e-02, -2.4674e-02, -5.2552e-02,\n",
       "                        8.1754e-03, -6.7513e-02, -6.3654e-02, -6.0554e-02,  3.4656e-03,\n",
       "                        4.3951e-02,  4.3763e-04,  4.6911e-02, -4.0650e-02,  8.1108e-03,\n",
       "                        4.9308e-02, -2.8055e-02, -3.6973e-02, -3.8794e-02,  3.6890e-02,\n",
       "                       -8.7002e-03, -2.3258e-02, -1.4505e-03,  6.3821e-02, -9.4099e-03,\n",
       "                        1.8729e-02, -1.8332e-02, -7.2863e-03,  4.2050e-02,  8.9105e-03,\n",
       "                       -3.4666e-02, -5.2832e-02, -2.6413e-03,  3.6740e-02,  3.6783e-02,\n",
       "                       -9.1141e-02, -4.9070e-02, -5.7922e-02,  1.7532e-02, -2.7993e-02,\n",
       "                       -6.6910e-03, -3.8200e-02,  1.6984e-02, -5.0075e-02,  3.3915e-02,\n",
       "                       -1.1655e-01,  7.8977e-02,  2.9659e-02, -4.8250e-02,  4.6330e-02,\n",
       "                       -3.8524e-02, -1.6804e-02,  5.5675e-02, -4.8627e-02, -1.6903e-02,\n",
       "                        1.1143e-01,  6.0789e-03,  2.8425e-03,  5.1793e-02,  7.6339e-02,\n",
       "                       -9.0001e-02,  6.4250e-02, -1.1304e-01,  5.0298e-02, -1.1978e-02,\n",
       "                        1.8867e-02, -3.5110e-02,  4.3709e-02,  4.8345e-02, -3.3942e-02,\n",
       "                       -1.5868e-03, -1.3175e-02, -1.9755e-02,  1.1528e-02,  3.6021e-02,\n",
       "                       -3.0468e-02,  4.8268e-02,  1.9079e-02,  5.6180e-02, -1.8375e-02,\n",
       "                        1.3579e-02,  1.0582e-02, -1.5795e-02, -2.3993e-02, -7.3625e-02,\n",
       "                        3.0209e-02,  1.0952e-02, -6.5093e-02, -4.4077e-03,  2.9001e-02,\n",
       "                        1.0402e-02,  2.1803e-02, -1.0994e-01,  1.7301e-03, -3.8749e-03,\n",
       "                        3.6820e-02,  8.7086e-02, -7.0026e-02, -2.0946e-02,  1.7501e-02,\n",
       "                       -6.5974e-02, -3.9952e-02,  1.5183e-02, -4.6328e-02, -3.3932e-02,\n",
       "                       -1.9495e-02, -7.0256e-02, -4.9115e-03, -1.6779e-02, -5.5179e-03,\n",
       "                       -6.2841e-02,  6.3454e-02,  3.6445e-02,  2.1023e-02, -3.7533e-03,\n",
       "                        4.5061e-02, -5.4394e-02, -4.5250e-02,  6.6044e-02, -6.5865e-02,\n",
       "                        1.6418e-02, -1.3292e-02, -2.5683e-02, -4.9214e-03,  1.3169e-02,\n",
       "                       -5.6789e-02,  4.0808e-02,  2.9604e-02, -5.3846e-02, -9.0585e-03,\n",
       "                        2.8123e-02, -3.5235e-02,  3.2924e-04,  1.3968e-02,  3.5993e-02,\n",
       "                        5.1427e-02])),\n",
       "              ('head_x.0.weight',\n",
       "               tensor([[ 0.0018,  0.0642, -0.0237,  ...,  0.0980,  0.0170, -0.0178],\n",
       "                       [ 0.0113,  0.0350,  0.0308,  ..., -0.0644, -0.0420, -0.0504],\n",
       "                       [-0.0112,  0.0312,  0.0323,  ...,  0.0056,  0.0491, -0.0670],\n",
       "                       ...,\n",
       "                       [ 0.0434,  0.0058,  0.0431,  ..., -0.0424,  0.0088,  0.0257],\n",
       "                       [ 0.0176,  0.0274, -0.1194,  ...,  0.0349, -0.0116,  0.0050],\n",
       "                       [ 0.0642, -0.0258,  0.1102,  ...,  0.0205,  0.0311,  0.0040]])),\n",
       "              ('head_x.0.bias',\n",
       "               tensor([ 0.0711, -0.0314,  0.0023,  0.0630,  0.0290, -0.0241,  0.0837, -0.0188,\n",
       "                       -0.0061,  0.0309, -0.0372,  0.0033,  0.0377, -0.0583,  0.0494,  0.0622,\n",
       "                       -0.0026, -0.0233,  0.0300,  0.0301, -0.0279, -0.0259, -0.0330, -0.0400,\n",
       "                        0.0269, -0.0347, -0.0102, -0.0552,  0.0538, -0.0615,  0.0694, -0.0218,\n",
       "                       -0.0668, -0.0523, -0.0337,  0.0367,  0.0159, -0.0057, -0.0136,  0.0156,\n",
       "                       -0.0504,  0.0243,  0.0565,  0.0525,  0.0056,  0.0505, -0.0332,  0.0561,\n",
       "                        0.0390,  0.0238,  0.0573, -0.0489,  0.0308,  0.0121, -0.0228,  0.0279,\n",
       "                        0.0597, -0.0260, -0.0056, -0.0239, -0.0301,  0.0586, -0.0224,  0.0336])),\n",
       "              ('head_x.2.weight',\n",
       "               tensor([[-0.0314, -0.1435, -0.0028, -0.1067,  0.0996,  0.1140,  0.1060,  0.0053,\n",
       "                         0.0967,  0.0961, -0.0523,  0.0974, -0.0170,  0.0221, -0.0497, -0.0286,\n",
       "                         0.1218, -0.1282, -0.0767,  0.0923, -0.0829, -0.0974,  0.1621, -0.0860,\n",
       "                         0.1028,  0.0872,  0.1616,  0.0086, -0.1555,  0.0180,  0.0952,  0.0361,\n",
       "                        -0.0456,  0.0745, -0.1565,  0.1418, -0.0751, -0.0395, -0.0679, -0.0688,\n",
       "                        -0.1650, -0.0442, -0.0031,  0.1643,  0.1020, -0.1249,  0.0990, -0.0591,\n",
       "                        -0.1485,  0.0525,  0.0454,  0.1052, -0.1269,  0.0782,  0.1472, -0.0536,\n",
       "                        -0.0053, -0.0915, -0.0793,  0.0497,  0.0748, -0.0616,  0.1183, -0.0780],\n",
       "                       [-0.1210, -0.0992,  0.0161,  0.0855, -0.1696, -0.0866, -0.0592, -0.0872,\n",
       "                         0.0811, -0.0526, -0.1180,  0.0607, -0.0969,  0.1598, -0.1660, -0.1541,\n",
       "                        -0.0883,  0.0409,  0.1303,  0.0293, -0.0893,  0.0152, -0.0662,  0.1436,\n",
       "                        -0.1347,  0.0493,  0.0207,  0.0619, -0.0863,  0.0592, -0.0507, -0.0376,\n",
       "                        -0.0585,  0.0789,  0.0573, -0.0933,  0.0323, -0.0611, -0.1096,  0.1297,\n",
       "                        -0.0115, -0.0836,  0.0946, -0.0887,  0.1603, -0.1576,  0.1049, -0.0563,\n",
       "                        -0.1007, -0.1358,  0.1441,  0.1322, -0.0281,  0.1381, -0.0614, -0.0199,\n",
       "                         0.1095,  0.0793,  0.0988, -0.0560,  0.0962, -0.0719, -0.0144,  0.1627]])),\n",
       "              ('head_x.2.bias', tensor([ 0.0960, -0.0475])),\n",
       "              ('head_lam.0.weight',\n",
       "               tensor([[ 0.0542,  0.0374, -0.0428,  ..., -0.0572,  0.0738, -0.0220],\n",
       "                       [ 0.0190,  0.0048, -0.0072,  ..., -0.0166, -0.0109, -0.0317],\n",
       "                       [-0.0668,  0.0406, -0.0109,  ..., -0.0758, -0.0301, -0.1229],\n",
       "                       ...,\n",
       "                       [-0.0307, -0.0265, -0.0513,  ..., -0.0069, -0.0273,  0.0434],\n",
       "                       [-0.0147, -0.0012, -0.0012,  ..., -0.0251,  0.0312,  0.0479],\n",
       "                       [-0.0416,  0.0658,  0.0842,  ..., -0.0190,  0.0282, -0.0343]])),\n",
       "              ('head_lam.0.bias',\n",
       "               tensor([ 0.0196, -0.0597, -0.0538,  0.0563, -0.0620,  0.0236, -0.0130,  0.0332,\n",
       "                        0.0351, -0.0248, -0.1063, -0.0416, -0.0333, -0.0390, -0.0501, -0.0009,\n",
       "                       -0.0895, -0.0234, -0.0232,  0.0541, -0.1061, -0.0063,  0.0310, -0.0565,\n",
       "                        0.0198, -0.0792, -0.0728,  0.1074, -0.0787, -0.0323, -0.0316, -0.0498,\n",
       "                        0.0169, -0.0258, -0.0130,  0.0170,  0.0444,  0.0250,  0.0260,  0.0117,\n",
       "                        0.0328, -0.0409, -0.0503, -0.0735,  0.0920,  0.0090, -0.0400,  0.0827,\n",
       "                       -0.0364,  0.0467, -0.0072, -0.0332,  0.0803, -0.0352, -0.0800, -0.0196,\n",
       "                        0.0331,  0.0445,  0.0163, -0.0147,  0.0495,  0.0329, -0.0355, -0.0725])),\n",
       "              ('head_lam.2.weight',\n",
       "               tensor([[ 0.1057, -0.1100, -0.1196, -0.0358, -0.0972, -0.0579, -0.0166,  0.1243,\n",
       "                         0.1030, -0.0051, -0.1528, -0.1340,  0.1294, -0.0141, -0.1145,  0.0890,\n",
       "                        -0.1457, -0.1268, -0.0582,  0.0599, -0.1369,  0.0899, -0.0943, -0.1120,\n",
       "                        -0.0265, -0.0397, -0.0764,  0.0114, -0.0862, -0.0935,  0.1137, -0.0949,\n",
       "                        -0.0760, -0.1186, -0.0256,  0.0163,  0.0736, -0.0402,  0.0162, -0.0587,\n",
       "                         0.0115,  0.0586, -0.0871, -0.1433,  0.1104, -0.0120, -0.0323, -0.0357,\n",
       "                         0.0101,  0.0968, -0.0018,  0.0556,  0.0114,  0.0982,  0.1614,  0.1130,\n",
       "                         0.0591,  0.0340,  0.0296,  0.1099,  0.0225,  0.0422, -0.0241, -0.0929],\n",
       "                       [ 0.1192, -0.0561, -0.0735,  0.1178, -0.1071, -0.0261, -0.0790, -0.0858,\n",
       "                         0.0301, -0.0572, -0.1074,  0.1220, -0.0514,  0.1084, -0.0460,  0.0639,\n",
       "                        -0.0725, -0.1198, -0.0156, -0.0983, -0.0194,  0.1229, -0.0144,  0.0566,\n",
       "                        -0.0280, -0.0528, -0.1184,  0.0098, -0.1487, -0.0815, -0.1066, -0.0739,\n",
       "                         0.0089,  0.0317, -0.1023, -0.1491, -0.0928,  0.0981, -0.0766,  0.0102,\n",
       "                         0.0211, -0.1029, -0.0646,  0.0903,  0.0374,  0.0972, -0.1584,  0.0451,\n",
       "                        -0.0250, -0.0783, -0.0010,  0.1071,  0.0285, -0.0744, -0.0948, -0.0972,\n",
       "                         0.0964, -0.0704,  0.1311, -0.0228, -0.0472, -0.1261, -0.0700, -0.0884]])),\n",
       "              ('head_lam.2.bias', tensor([-0.0742, -0.0574]))]),\n",
       " 'optimizer': {'state': {0: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[-2.4318e-04,  1.5544e-04,  1.0674e-05,  ...,  1.2699e-04,\n",
       "              2.5462e-04,  2.6815e-07],\n",
       "            [ 1.1061e-04, -1.2550e-04, -1.2330e-04,  ...,  1.3781e-04,\n",
       "              1.6619e-04, -6.8074e-05],\n",
       "            [-2.0711e-04,  3.9211e-05,  1.0507e-05,  ...,  5.9106e-05,\n",
       "              2.6075e-04, -2.6327e-05],\n",
       "            ...,\n",
       "            [-3.1120e-05,  6.1929e-05,  4.9881e-07,  ...,  1.4349e-04,\n",
       "              2.2669e-05, -9.4684e-05],\n",
       "            [ 8.7577e-05,  2.2743e-05, -8.5159e-05,  ..., -1.9150e-06,\n",
       "             -2.2533e-05, -2.4365e-04],\n",
       "            [-5.7613e-05, -3.6345e-05,  5.8673e-05,  ..., -1.2038e-04,\n",
       "              6.3180e-05,  9.0407e-05]]),\n",
       "    'exp_avg_sq': tensor([[2.2333e-06, 2.6394e-06, 1.3875e-06,  ..., 5.7616e-07, 1.3967e-06,\n",
       "             1.4844e-06],\n",
       "            [4.5898e-06, 3.3363e-06, 4.6258e-06,  ..., 1.0658e-06, 2.2598e-06,\n",
       "             2.3398e-06],\n",
       "            [1.5958e-06, 1.3886e-06, 1.3576e-06,  ..., 5.1069e-07, 1.2164e-06,\n",
       "             1.1011e-06],\n",
       "            ...,\n",
       "            [1.3882e-06, 1.2575e-06, 1.2347e-06,  ..., 4.7505e-07, 1.0516e-06,\n",
       "             1.1483e-06],\n",
       "            [1.2101e-06, 1.6947e-06, 1.4086e-06,  ..., 5.0366e-07, 9.7499e-07,\n",
       "             1.0973e-06],\n",
       "            [8.6598e-07, 8.6749e-07, 1.1389e-06,  ..., 3.5673e-07, 8.2296e-07,\n",
       "             8.1250e-07]])},\n",
       "   1: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([ 2.5080e-04, -8.8663e-05,  2.6187e-04, -2.7803e-04, -8.5559e-05,\n",
       "            -1.2686e-04, -6.0644e-05,  1.2853e-04, -4.4968e-04, -3.7892e-04,\n",
       "            -4.2397e-04,  4.1579e-04,  3.9048e-04, -8.3121e-05, -5.2176e-04,\n",
       "            -1.9813e-04, -2.1691e-04,  8.4402e-04, -3.7904e-04, -3.1795e-04,\n",
       "             2.8496e-04, -9.1879e-04,  2.1410e-04, -4.6407e-05,  8.6101e-05,\n",
       "             4.9738e-04, -6.3899e-05,  3.6980e-06,  4.4564e-04,  2.6594e-05,\n",
       "             5.0438e-04,  3.6434e-05, -1.0288e-04,  4.7261e-05, -1.3790e-04,\n",
       "             1.6706e-04,  1.9144e-04, -5.6744e-05,  3.0011e-04,  1.5354e-04,\n",
       "             2.7439e-04,  6.4737e-04,  3.4776e-04,  3.6178e-04,  1.7252e-05,\n",
       "             1.1857e-05,  1.7781e-06,  2.8266e-05, -2.5720e-05, -3.5209e-04,\n",
       "            -3.1624e-04, -5.4748e-04,  2.6828e-04, -2.2547e-05,  2.3395e-04,\n",
       "            -8.0472e-05, -4.5777e-05,  1.0625e-04,  2.8901e-04,  7.5522e-05,\n",
       "            -4.7083e-04,  1.6367e-04, -9.9006e-05,  3.9770e-04,  2.6648e-04,\n",
       "            -2.3883e-04,  2.1123e-07,  2.5413e-04, -4.3399e-04, -1.0605e-04,\n",
       "            -7.5417e-04, -3.4675e-04,  2.0883e-04,  1.9603e-04, -2.1489e-04,\n",
       "             9.8483e-05, -1.5814e-04,  3.5251e-05,  5.8697e-05,  7.7499e-05,\n",
       "            -2.4561e-04, -6.0385e-04,  8.1282e-05,  3.7986e-04, -1.0946e-04,\n",
       "            -2.0294e-04, -1.6963e-04,  3.8284e-04, -8.1591e-05,  2.2663e-04,\n",
       "             4.2064e-04,  1.8113e-04,  2.6649e-04,  1.3799e-04, -4.3921e-04,\n",
       "            -2.4394e-04, -4.4066e-04,  7.7786e-05,  6.4588e-04, -9.8667e-04,\n",
       "            -5.4656e-05,  1.7147e-04, -3.4861e-04, -6.4216e-04,  5.4650e-05,\n",
       "            -2.5656e-04,  3.6729e-05, -3.5123e-04,  5.2062e-04,  3.9652e-05,\n",
       "            -2.9681e-04, -1.2031e-04,  1.7965e-04,  1.9828e-04, -1.1429e-04,\n",
       "            -2.6657e-04,  3.1543e-04, -2.1989e-04,  1.9038e-04, -1.0643e-04,\n",
       "             4.7616e-04, -1.4513e-04,  2.9519e-04, -2.4696e-04, -1.5592e-04,\n",
       "            -1.9384e-04,  5.6564e-04,  1.1492e-04, -4.1734e-05, -3.1059e-04,\n",
       "             2.4936e-04, -2.9368e-04,  9.4202e-05,  3.0921e-04,  1.7515e-05,\n",
       "            -1.1535e-04, -2.9468e-04,  1.9070e-04, -9.0252e-05,  2.5789e-04,\n",
       "             1.2923e-04,  6.5330e-04, -1.3755e-04,  2.3181e-04,  2.1403e-04,\n",
       "             1.2684e-04,  5.2464e-06,  1.0502e-05, -5.1431e-04, -3.9736e-04,\n",
       "             2.9912e-04, -1.3308e-04, -4.0476e-04, -3.0417e-04,  3.9170e-04,\n",
       "            -2.5231e-04, -1.2955e-04,  5.8699e-04,  2.3157e-04,  1.9375e-05,\n",
       "            -2.4768e-04,  2.1703e-04,  1.4100e-04, -2.7418e-04,  3.9422e-04,\n",
       "             1.3341e-04,  9.0701e-05,  4.9037e-04, -1.0466e-04, -2.1301e-06,\n",
       "            -1.2591e-04,  1.6418e-05, -3.1950e-04, -1.2177e-04, -3.3751e-04,\n",
       "             1.7945e-04,  2.2812e-04,  2.3210e-04, -4.5780e-04,  1.3944e-04,\n",
       "             8.1100e-05, -2.7987e-04, -2.9456e-04, -1.8247e-04, -6.4116e-04,\n",
       "             3.3668e-04,  1.5542e-04, -3.3635e-04, -2.8427e-04,  4.1720e-04,\n",
       "            -3.5056e-04, -6.7317e-05, -1.0486e-04,  5.3462e-05,  6.0251e-04,\n",
       "            -1.2802e-04, -6.0862e-05, -1.3977e-04,  1.9423e-04, -1.7597e-04,\n",
       "            -2.8029e-04, -6.1058e-04,  3.6914e-04, -4.1182e-05,  2.4051e-04,\n",
       "             3.1428e-04,  3.6232e-04, -5.6520e-05,  1.6084e-04, -2.1657e-04,\n",
       "            -2.1217e-04, -7.8536e-05, -1.2885e-04, -1.8259e-05,  2.7043e-04,\n",
       "            -2.4750e-04, -5.2355e-04, -1.1278e-04, -6.8598e-05, -2.1201e-04,\n",
       "             8.5887e-05, -6.6999e-05,  1.3363e-04,  1.0610e-04,  2.7301e-04,\n",
       "            -4.4430e-04, -4.5381e-04, -4.5614e-04,  1.7993e-04, -8.0914e-05,\n",
       "            -2.6775e-04,  3.2587e-04,  8.6137e-05, -3.4352e-04, -2.8956e-04,\n",
       "             1.4173e-04, -5.0445e-04, -4.4173e-04,  4.1748e-04,  2.4759e-04,\n",
       "             1.3238e-04,  2.1109e-04, -2.1329e-04,  1.0826e-04,  6.1163e-04,\n",
       "             9.8004e-05,  7.0827e-04, -1.4484e-04, -1.2218e-04, -1.2111e-04,\n",
       "            -4.4078e-04,  2.3431e-04, -8.8515e-05,  5.2806e-05, -3.3305e-05,\n",
       "             1.6167e-04]),\n",
       "    'exp_avg_sq': tensor([4.2908e-06, 7.8489e-06, 2.8775e-06, 5.7867e-06, 5.9216e-06, 4.6350e-06,\n",
       "            1.6704e-06, 9.2639e-06, 3.9904e-06, 5.2146e-06, 4.9337e-06, 3.8991e-06,\n",
       "            7.2354e-06, 1.9875e-06, 9.3868e-06, 1.8866e-06, 2.2819e-06, 1.1676e-05,\n",
       "            4.6710e-06, 2.5645e-06, 5.3032e-06, 1.2961e-05, 1.6576e-06, 3.3450e-07,\n",
       "            5.0182e-06, 6.5174e-06, 3.1006e-06, 3.4394e-06, 4.0068e-06, 2.2306e-06,\n",
       "            9.8176e-06, 4.9275e-06, 2.5070e-06, 3.2225e-06, 2.7295e-06, 1.8991e-06,\n",
       "            1.3388e-06, 7.6591e-07, 2.1832e-06, 2.4435e-06, 5.1538e-06, 5.9104e-06,\n",
       "            2.3958e-05, 4.2614e-06, 8.4216e-06, 2.7957e-06, 2.5993e-06, 1.4248e-06,\n",
       "            6.1089e-06, 2.5884e-06, 3.8522e-06, 5.0009e-06, 3.0819e-06, 4.4919e-06,\n",
       "            7.5997e-06, 2.4104e-06, 1.6069e-06, 8.1766e-06, 2.9359e-06, 3.1283e-07,\n",
       "            4.8978e-06, 5.5087e-06, 3.8369e-06, 5.3642e-06, 2.7432e-06, 4.0420e-06,\n",
       "            1.7193e-06, 7.6391e-06, 4.2127e-06, 5.0860e-06, 8.9140e-06, 5.3846e-06,\n",
       "            2.5275e-06, 1.2416e-05, 1.7223e-06, 1.4485e-06, 3.6190e-06, 4.5972e-06,\n",
       "            1.3478e-06, 1.4379e-06, 5.8345e-06, 6.2913e-06, 3.5545e-06, 4.8548e-06,\n",
       "            2.2171e-06, 2.8619e-06, 1.5668e-06, 1.1515e-05, 3.5081e-06, 2.5284e-06,\n",
       "            4.1118e-06, 2.0316e-06, 8.3516e-06, 1.7788e-06, 1.0691e-05, 2.1698e-06,\n",
       "            6.0282e-06, 8.9464e-07, 1.1323e-05, 1.4716e-05, 6.8833e-06, 2.7908e-06,\n",
       "            3.5168e-06, 8.5991e-06, 5.3594e-06, 2.4025e-06, 2.2909e-06, 4.1734e-06,\n",
       "            4.6125e-06, 3.1255e-06, 2.5957e-06, 8.7684e-07, 1.8068e-06, 1.3182e-06,\n",
       "            6.4918e-07, 8.7539e-06, 2.9655e-06, 3.9814e-06, 2.9650e-06, 1.7004e-06,\n",
       "            5.6005e-06, 2.1697e-06, 6.6833e-06, 3.8371e-06, 2.0517e-06, 2.4011e-06,\n",
       "            9.6300e-06, 3.1491e-06, 4.1758e-06, 4.9992e-06, 2.9884e-06, 3.8210e-06,\n",
       "            2.5282e-06, 8.0641e-06, 1.2390e-06, 5.2925e-06, 4.7706e-06, 3.0377e-06,\n",
       "            2.6005e-06, 2.4580e-06, 4.0680e-07, 1.2954e-05, 2.5276e-06, 1.8150e-06,\n",
       "            2.3760e-06, 1.3875e-06, 7.9377e-06, 7.8776e-06, 1.9341e-05, 7.2075e-06,\n",
       "            3.6874e-06, 4.1853e-06, 2.9760e-06, 2.5194e-06, 3.7754e-06, 3.5540e-06,\n",
       "            3.3300e-06, 1.2040e-05, 2.8537e-06, 1.8476e-06, 5.3135e-06, 5.1781e-06,\n",
       "            1.4855e-06, 9.0253e-06, 7.5143e-06, 1.0481e-06, 4.1254e-06, 9.2648e-06,\n",
       "            9.2290e-07, 5.0615e-06, 2.4512e-06, 3.5592e-06, 2.1834e-06, 1.6023e-06,\n",
       "            4.1102e-06, 7.0175e-06, 2.8777e-06, 5.0754e-06, 1.0547e-05, 1.8612e-06,\n",
       "            3.8443e-06, 2.4572e-06, 4.3867e-06, 1.2251e-06, 6.6037e-06, 6.9923e-06,\n",
       "            5.5499e-06, 2.7514e-06, 2.6542e-06, 7.8045e-06, 6.0548e-06, 2.5512e-06,\n",
       "            3.7983e-06, 5.4572e-06, 1.5268e-05, 6.7772e-07, 1.9290e-06, 4.6183e-06,\n",
       "            1.3090e-06, 2.0825e-06, 4.0439e-06, 8.7845e-06, 4.3796e-06, 1.9236e-06,\n",
       "            2.0421e-06, 4.7737e-06, 7.6247e-06, 3.0890e-06, 4.4428e-06, 2.3516e-06,\n",
       "            4.1095e-06, 2.2423e-06, 6.7099e-07, 5.1088e-06, 2.1286e-06, 3.1007e-06,\n",
       "            3.4469e-06, 3.2401e-06, 4.9188e-06, 4.2836e-06, 4.7883e-06, 1.7630e-06,\n",
       "            4.6006e-06, 4.5461e-06, 4.8733e-06, 5.4161e-06, 4.1474e-06, 8.5380e-06,\n",
       "            6.9199e-06, 2.2243e-06, 5.5377e-06, 4.0023e-06, 1.4270e-06, 3.6084e-06,\n",
       "            5.2486e-06, 8.0716e-06, 3.7557e-06, 4.3485e-06, 5.6884e-06, 3.2903e-06,\n",
       "            2.9240e-06, 2.6160e-06, 1.7581e-06, 2.0671e-06, 4.6954e-06, 1.4154e-06,\n",
       "            7.4723e-06, 7.4851e-06, 2.3217e-06, 2.2622e-06, 5.2224e-06, 3.4783e-06,\n",
       "            7.3517e-06, 2.5314e-06, 2.8966e-06, 2.1852e-06])},\n",
       "   2: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[ 3.0852e-05, -3.3898e-05,  9.2580e-05,  ...,  1.4897e-05,\n",
       "              5.8797e-05,  1.1978e-04],\n",
       "            [ 4.6201e-06, -1.4772e-05, -1.8145e-06,  ...,  3.0231e-05,\n",
       "              3.4766e-06,  9.1952e-06],\n",
       "            [-4.8140e-05, -8.2298e-07,  1.9160e-05,  ...,  1.6197e-05,\n",
       "              1.4204e-04,  5.2299e-05],\n",
       "            ...,\n",
       "            [-7.8260e-05, -3.4008e-06, -6.5087e-05,  ...,  8.0740e-05,\n",
       "              8.8988e-05,  2.0506e-05],\n",
       "            [-2.5073e-06, -2.4351e-05, -6.9109e-05,  ..., -1.2757e-05,\n",
       "             -1.0074e-04, -8.1476e-05],\n",
       "            [ 5.8991e-05, -4.5995e-05,  7.8922e-05,  ..., -3.9819e-05,\n",
       "              4.4938e-05,  1.0162e-04]]),\n",
       "    'exp_avg_sq': tensor([[6.1947e-07, 2.6534e-07, 8.1945e-07,  ..., 8.0008e-07, 7.3531e-07,\n",
       "             1.0945e-06],\n",
       "            [1.3165e-08, 2.3246e-08, 3.0718e-08,  ..., 2.0127e-08, 2.9067e-08,\n",
       "             5.5956e-08],\n",
       "            [5.4096e-07, 5.1815e-07, 1.1629e-06,  ..., 1.7732e-06, 1.5971e-06,\n",
       "             2.8458e-06],\n",
       "            ...,\n",
       "            [3.7564e-07, 2.7241e-07, 4.2857e-07,  ..., 5.0626e-07, 4.6917e-07,\n",
       "             7.4701e-07],\n",
       "            [7.4295e-07, 6.4809e-07, 5.4593e-07,  ..., 9.8976e-07, 1.5911e-06,\n",
       "             2.0495e-06],\n",
       "            [9.5047e-07, 5.4746e-07, 7.6320e-07,  ..., 1.4797e-06, 9.9648e-07,\n",
       "             1.6445e-06]])},\n",
       "   3: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([-4.1182e-04,  7.5145e-06,  1.3686e-04, -3.5890e-05,  8.4171e-05,\n",
       "            -3.0778e-04, -9.2707e-06, -9.4593e-05,  3.0945e-05,  1.5066e-04,\n",
       "             1.4609e-05, -2.6891e-05,  3.0749e-05,  2.1192e-05, -5.4381e-05,\n",
       "             5.7145e-05, -4.4686e-05, -2.8598e-05,  7.6619e-06, -2.1602e-04,\n",
       "            -1.0765e-04, -1.1202e-04, -2.2172e-04,  1.2982e-05,  4.9573e-05,\n",
       "             1.1489e-05, -2.3038e-04,  8.6459e-05, -1.9744e-04,  2.1635e-05,\n",
       "             2.3663e-04, -1.6076e-05,  1.7757e-05, -1.3388e-04,  1.7292e-04,\n",
       "             1.6045e-04, -1.8434e-05, -1.3649e-06, -2.3730e-04, -6.1476e-05,\n",
       "             2.2919e-04,  1.7923e-04,  4.3520e-04,  8.4695e-05, -1.1423e-04,\n",
       "             4.8380e-05, -1.0420e-04, -1.1251e-04, -1.5164e-04, -1.8309e-04,\n",
       "             1.3767e-04,  2.7140e-04,  1.0881e-04,  8.4948e-05,  1.2450e-04,\n",
       "            -4.7710e-05,  3.6207e-05,  5.0685e-05,  1.7614e-04,  1.6134e-06,\n",
       "            -2.7762e-06,  2.1209e-04,  2.3144e-04,  4.5545e-04, -3.0730e-05,\n",
       "            -2.2942e-04,  7.3733e-06, -1.5272e-04, -1.2889e-04, -1.6507e-04,\n",
       "            -5.8080e-06,  2.7184e-04,  8.5652e-07, -2.7984e-04,  2.4098e-06,\n",
       "             2.5201e-04, -1.2150e-05,  3.9181e-06,  3.6432e-05, -7.8194e-05,\n",
       "            -1.9845e-04, -1.2860e-04,  3.6944e-05, -1.4600e-04,  1.9971e-04,\n",
       "            -3.9126e-05, -1.4391e-04,  4.5077e-05,  6.6783e-05,  1.1847e-04,\n",
       "            -1.6695e-05,  1.7250e-06, -9.3795e-05,  1.4517e-04,  4.9842e-05,\n",
       "            -3.2847e-04, -2.1123e-04, -2.6084e-05, -4.3890e-05,  3.2578e-05,\n",
       "            -1.4076e-04,  3.2671e-05, -1.3161e-04, -1.0472e-04, -9.1440e-05,\n",
       "             7.6412e-05,  7.8249e-05,  2.3179e-04,  2.6099e-04, -1.0243e-04,\n",
       "            -1.5729e-05, -9.5857e-06,  2.0049e-06, -1.3854e-04,  8.1463e-05,\n",
       "            -1.0975e-04, -3.4506e-05, -4.9404e-06,  4.7637e-05,  1.2490e-04,\n",
       "            -2.1821e-06,  1.4742e-04,  2.5347e-06, -5.1659e-05, -1.8420e-05,\n",
       "            -3.0602e-04,  3.7228e-05,  1.0136e-04, -1.4504e-05,  1.4121e-04,\n",
       "            -2.3034e-04,  5.2128e-05,  9.4685e-05,  2.2464e-04,  1.7073e-04,\n",
       "             7.8556e-05, -1.4617e-04, -3.4612e-05,  8.5833e-05,  2.1758e-05,\n",
       "            -2.7345e-05, -3.0488e-04, -5.5154e-05, -2.4757e-04, -1.1272e-05,\n",
       "             3.9313e-05,  1.7917e-04,  7.3451e-05, -9.2541e-05, -4.5588e-05,\n",
       "            -1.6057e-04, -3.5770e-04, -6.7269e-05, -8.0344e-05,  1.8824e-05,\n",
       "             1.4449e-06, -1.5896e-05,  6.7898e-05,  8.8767e-06, -2.1214e-04,\n",
       "             2.8252e-05, -2.5009e-06, -9.1457e-05,  5.1837e-05, -7.7503e-05,\n",
       "            -1.5490e-04,  2.8231e-05,  2.8614e-05,  4.3290e-05,  1.1430e-04,\n",
       "             2.3901e-04, -9.2581e-05,  2.6473e-06,  2.6276e-05,  2.5445e-05,\n",
       "             1.8162e-05, -3.0646e-04, -1.6214e-05, -1.6000e-05,  5.7581e-05,\n",
       "             2.0052e-04,  1.7215e-04,  1.3208e-04,  2.9142e-05,  2.2991e-04,\n",
       "             3.5612e-05, -1.1949e-04, -7.7583e-05, -7.7386e-05, -7.0204e-05,\n",
       "             6.3781e-05,  1.0830e-04, -1.0234e-04, -7.6943e-06,  6.5429e-05,\n",
       "            -8.9428e-05, -8.1306e-06,  1.5039e-05, -1.4385e-04,  5.5015e-05,\n",
       "            -7.0284e-05,  2.3574e-04,  2.0169e-04,  8.2295e-05,  1.1978e-05,\n",
       "             2.5122e-05, -2.4908e-05, -6.1540e-05,  9.7705e-05,  7.2369e-05,\n",
       "             1.2608e-04,  3.2191e-05,  1.4919e-06, -1.8512e-04,  2.0177e-04,\n",
       "             3.1456e-04,  3.1750e-05,  2.5194e-05,  1.3183e-04, -1.0805e-05,\n",
       "             1.0629e-04, -1.5957e-05,  3.6144e-05, -3.1510e-05,  7.2465e-05,\n",
       "            -1.5619e-04,  1.8066e-04, -9.1677e-05, -2.3242e-04,  5.5073e-05,\n",
       "            -3.1852e-05, -1.8599e-04, -4.7842e-05, -2.4109e-05, -7.8638e-05,\n",
       "             1.9365e-05,  9.3203e-05,  3.9909e-05,  2.3532e-05,  2.1061e-04,\n",
       "             3.9623e-04, -9.5905e-06,  4.1777e-05, -2.1736e-04, -1.4244e-05,\n",
       "            -9.3004e-05,  1.8053e-04,  1.7452e-05, -1.5467e-04, -3.5071e-05,\n",
       "            -3.3554e-04,  1.8150e-04, -6.4680e-05,  1.1667e-04,  8.1661e-05,\n",
       "            -2.6904e-04]),\n",
       "    'exp_avg_sq': tensor([2.9439e-06, 1.6570e-07, 5.8273e-06, 1.6689e-06, 3.7672e-07, 3.0017e-06,\n",
       "            5.0509e-06, 5.9526e-07, 5.3409e-07, 1.3941e-06, 8.5732e-07, 1.9294e-06,\n",
       "            1.0556e-06, 1.0081e-06, 2.9197e-06, 3.9995e-07, 1.8953e-06, 1.4477e-07,\n",
       "            8.9832e-07, 1.1880e-06, 7.5480e-07, 2.8341e-07, 1.3088e-06, 5.0493e-08,\n",
       "            9.7476e-07, 7.2744e-08, 1.1964e-06, 5.6597e-07, 1.4176e-06, 1.3012e-07,\n",
       "            4.1899e-06, 4.1417e-07, 1.5354e-07, 6.6198e-07, 2.9289e-06, 8.4159e-07,\n",
       "            6.8414e-07, 6.2671e-08, 3.8950e-06, 1.4495e-06, 1.7044e-06, 7.0738e-07,\n",
       "            3.3776e-06, 2.0272e-06, 8.5296e-07, 1.6827e-06, 1.8662e-06, 5.6640e-07,\n",
       "            3.0604e-06, 2.9501e-06, 3.1517e-06, 3.3779e-06, 1.1041e-06, 4.3146e-06,\n",
       "            5.0571e-07, 3.5030e-07, 1.8270e-07, 6.2741e-07, 1.4805e-06, 2.1132e-07,\n",
       "            1.6148e-07, 2.5902e-06, 2.1579e-06, 3.8086e-06, 2.1709e-07, 2.0558e-06,\n",
       "            1.6348e-07, 7.6498e-07, 1.1038e-06, 1.1979e-06, 5.2690e-07, 2.3234e-06,\n",
       "            1.5630e-06, 2.4033e-06, 3.4045e-07, 1.9098e-06, 7.0305e-07, 2.4291e-06,\n",
       "            6.7608e-07, 1.1220e-06, 9.3474e-07, 5.3299e-06, 6.4414e-07, 5.6166e-07,\n",
       "            3.0605e-06, 1.1941e-06, 2.3474e-06, 1.7129e-06, 6.1910e-07, 9.5669e-07,\n",
       "            7.8754e-07, 4.8446e-07, 1.2794e-06, 9.4868e-07, 1.9108e-07, 2.8434e-06,\n",
       "            1.2048e-06, 1.4028e-06, 1.1241e-06, 2.9784e-07, 1.4410e-06, 1.1940e-06,\n",
       "            3.0210e-06, 7.6988e-07, 4.1419e-07, 3.0380e-06, 9.0043e-07, 9.9872e-07,\n",
       "            4.5522e-06, 1.1077e-06, 3.4211e-06, 2.2659e-07, 7.7518e-07, 1.6305e-06,\n",
       "            3.9607e-07, 6.0602e-07, 9.2422e-08, 6.7000e-08, 2.4768e-07, 1.4260e-06,\n",
       "            1.0185e-07, 1.4475e-06, 6.3960e-06, 6.8282e-07, 4.7870e-07, 5.8628e-06,\n",
       "            1.9774e-06, 1.3227e-06, 5.8922e-08, 5.3780e-07, 4.2152e-06, 5.9601e-07,\n",
       "            1.2034e-06, 2.8194e-06, 9.4038e-07, 5.6792e-07, 6.4072e-07, 2.2751e-07,\n",
       "            5.5945e-07, 3.5438e-07, 5.9795e-07, 2.5901e-06, 3.0055e-07, 5.2081e-06,\n",
       "            1.9714e-07, 3.9154e-07, 2.9495e-06, 2.2253e-06, 1.2839e-06, 1.0625e-06,\n",
       "            3.3290e-06, 4.1191e-06, 6.5582e-07, 3.3148e-07, 3.0593e-07, 1.2379e-06,\n",
       "            1.1487e-06, 9.7689e-08, 1.7699e-07, 1.2838e-06, 1.3312e-06, 1.7322e-07,\n",
       "            7.6815e-07, 5.2253e-06, 2.4591e-07, 9.6726e-07, 1.5058e-06, 8.7333e-07,\n",
       "            4.9604e-06, 9.6324e-07, 2.9550e-06, 1.0156e-06, 6.4639e-07, 2.3045e-06,\n",
       "            6.3426e-08, 2.3759e-07, 2.6691e-06, 5.4476e-07, 1.6799e-07, 2.0917e-06,\n",
       "            7.3914e-07, 2.2073e-06, 1.7180e-06, 2.4534e-06, 8.4264e-07, 2.9676e-07,\n",
       "            4.1384e-06, 1.5685e-07, 5.3502e-07, 1.5256e-06, 6.9486e-07, 2.0443e-06,\n",
       "            8.6259e-07, 4.0017e-07, 1.7595e-06, 8.2356e-07, 9.6562e-08, 3.2903e-07,\n",
       "            5.0535e-06, 1.5904e-06, 1.5568e-07, 4.9464e-06, 2.8194e-06, 2.7627e-06,\n",
       "            1.3542e-07, 2.3439e-07, 1.6804e-06, 9.3226e-07, 1.9747e-06, 2.2875e-06,\n",
       "            6.7163e-07, 3.9878e-07, 1.7838e-06, 6.7643e-07, 6.4013e-06, 3.2264e-06,\n",
       "            4.5373e-07, 2.9941e-07, 2.4227e-06, 1.2586e-07, 1.0989e-06, 2.9700e-07,\n",
       "            4.3015e-07, 6.1718e-07, 1.7340e-06, 2.5340e-06, 1.5515e-06, 2.7379e-06,\n",
       "            2.5308e-06, 1.5979e-06, 5.3860e-07, 3.9234e-06, 1.4593e-06, 1.6071e-07,\n",
       "            1.4925e-06, 1.6877e-07, 3.0574e-06, 1.8759e-07, 2.0155e-07, 2.4698e-06,\n",
       "            2.8329e-06, 1.2465e-06, 3.3130e-07, 7.4088e-07, 4.3568e-07, 1.5431e-06,\n",
       "            3.7338e-06, 3.8335e-06, 1.6627e-06, 1.8930e-07, 2.8586e-06, 1.9098e-06,\n",
       "            1.4143e-06, 1.9827e-06, 4.0607e-06, 4.6815e-06])},\n",
       "   4: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[ 1.5590e-05, -1.9146e-05,  5.2447e-07,  ..., -4.9006e-05,\n",
       "             -4.1341e-05,  9.3259e-05],\n",
       "            [-2.7202e-04,  9.8166e-05, -1.2083e-04,  ..., -3.0845e-05,\n",
       "             -1.2798e-04, -2.1341e-04],\n",
       "            [-2.0088e-05,  7.9111e-05,  3.6940e-04,  ..., -2.8880e-05,\n",
       "             -1.1622e-05,  6.0075e-05],\n",
       "            ...,\n",
       "            [ 4.2363e-05, -1.8281e-05, -7.7546e-05,  ..., -1.9250e-05,\n",
       "              2.9825e-06,  9.0301e-06],\n",
       "            [ 7.1306e-05,  4.2205e-05,  8.9564e-05,  ..., -1.5089e-04,\n",
       "              4.2031e-06,  1.6133e-05],\n",
       "            [ 6.0173e-07, -6.8699e-05, -7.7359e-05,  ...,  3.3623e-05,\n",
       "              1.5572e-05, -2.8440e-05]]),\n",
       "    'exp_avg_sq': tensor([[6.8850e-07, 1.1495e-07, 1.4288e-06,  ..., 1.1147e-06, 4.9886e-07,\n",
       "             8.9157e-07],\n",
       "            [1.7388e-06, 4.8541e-07, 4.1138e-06,  ..., 1.3850e-06, 1.1120e-06,\n",
       "             2.1652e-06],\n",
       "            [2.8512e-06, 5.5696e-07, 7.2022e-06,  ..., 3.2934e-06, 2.1231e-06,\n",
       "             1.6233e-06],\n",
       "            ...,\n",
       "            [1.5602e-07, 4.6157e-08, 4.6440e-07,  ..., 1.5860e-07, 8.5363e-08,\n",
       "             2.6121e-07],\n",
       "            [1.0225e-06, 1.6966e-07, 2.0038e-06,  ..., 9.9482e-07, 8.6422e-07,\n",
       "             6.8283e-07],\n",
       "            [8.2199e-07, 1.9628e-07, 2.1631e-06,  ..., 1.3473e-06, 4.8350e-07,\n",
       "             8.6867e-07]])},\n",
       "   5: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([-8.4496e-05, -1.4617e-05, -2.0682e-04,  5.4721e-07,  2.0993e-05,\n",
       "            -8.2999e-05, -8.8509e-05,  1.0474e-04,  1.0409e-04, -5.2056e-05,\n",
       "            -4.0504e-05, -2.9206e-05,  1.0191e-05, -1.6450e-05, -1.1595e-04,\n",
       "             2.1159e-05, -6.6142e-05,  2.5308e-05, -5.2981e-05, -7.4533e-05,\n",
       "             4.6531e-05, -2.7886e-05, -2.6137e-04, -1.4356e-05, -2.4393e-04,\n",
       "            -1.0077e-05,  6.4174e-05,  9.1933e-05, -9.3372e-05, -7.8004e-05,\n",
       "            -2.7516e-05,  3.0351e-06, -9.2954e-06, -5.7157e-05, -1.4584e-04,\n",
       "            -1.3975e-05, -1.8802e-05, -4.4031e-05,  1.7608e-05, -3.5239e-06,\n",
       "             1.1771e-04, -1.2660e-04,  8.5672e-05, -7.4537e-05, -6.5437e-06,\n",
       "             8.2642e-05, -4.2842e-05,  2.4556e-06, -9.2508e-05, -4.0740e-05,\n",
       "             4.9339e-05, -1.6957e-04, -2.4926e-06,  8.7286e-06, -4.1078e-05,\n",
       "            -4.8373e-06,  1.2886e-04,  1.5821e-05, -4.9241e-06,  1.8658e-04,\n",
       "            -1.0842e-04,  3.8971e-05, -5.9468e-06,  1.7500e-04, -2.2442e-06,\n",
       "            -1.1965e-04,  5.0223e-05,  1.0944e-04,  4.6001e-05, -7.5649e-05,\n",
       "            -3.3306e-05, -2.9255e-05, -1.8651e-04, -6.6159e-05, -9.2349e-05,\n",
       "            -1.3203e-04, -2.9158e-05,  8.9007e-05,  2.7600e-05,  4.4195e-05,\n",
       "            -3.5373e-05,  1.0549e-04, -2.6964e-04, -2.5610e-05, -3.6022e-05,\n",
       "             6.0066e-05, -1.2093e-05, -4.2640e-05,  2.5991e-05,  1.2458e-05,\n",
       "            -2.8123e-05, -7.3817e-05,  6.7219e-06,  6.8560e-05,  7.4058e-06,\n",
       "            -3.5095e-05, -6.6115e-06, -1.2827e-04,  9.6371e-06,  4.5312e-05,\n",
       "             7.8331e-05,  1.1711e-06, -2.4366e-07, -6.7668e-05,  1.1370e-05,\n",
       "             4.7433e-05,  3.6406e-05, -2.0971e-05,  1.4118e-04, -6.5126e-05,\n",
       "            -9.9742e-05, -7.3759e-05,  4.2636e-05, -1.7167e-04,  2.1479e-05,\n",
       "            -6.6093e-05,  2.9703e-05, -1.1110e-04,  1.4559e-04, -8.0669e-05,\n",
       "            -5.2764e-05,  7.4646e-06,  1.1120e-05, -1.2927e-04,  3.3105e-05,\n",
       "            -1.2172e-04, -9.2386e-05, -1.0777e-04,  2.7975e-05,  1.3199e-04,\n",
       "             4.0716e-05, -1.5162e-05, -1.5061e-04, -8.9278e-05, -1.0180e-04,\n",
       "            -3.1145e-06,  9.4290e-05,  1.2986e-05,  1.1529e-04, -8.9452e-05,\n",
       "             3.6993e-05, -5.4136e-05, -5.8560e-05, -2.2860e-05, -8.6791e-05,\n",
       "            -3.0920e-05,  8.2277e-05, -1.7486e-04, -3.2538e-05,  8.8406e-05,\n",
       "             3.3818e-05,  2.6728e-05,  3.6340e-05, -2.2234e-05, -1.9947e-04,\n",
       "             1.3829e-04, -1.2947e-05,  2.4786e-05,  1.6980e-05,  3.0224e-05,\n",
       "             1.3488e-05, -1.5669e-04, -1.6154e-04, -4.1140e-05,  1.0627e-05,\n",
       "            -9.8213e-05, -4.2013e-06,  6.1550e-05, -1.4330e-04,  4.2775e-05,\n",
       "             1.4497e-04, -8.0152e-06,  1.3558e-05,  1.2656e-05, -5.6901e-05,\n",
       "             1.4601e-04,  1.8636e-04, -9.7772e-05, -7.1278e-05,  2.7786e-05,\n",
       "            -1.4486e-05,  8.9646e-05,  6.3516e-05, -3.2959e-05,  2.5339e-04,\n",
       "            -1.4565e-04, -8.2554e-05, -5.5909e-06,  2.4204e-04,  8.0970e-05,\n",
       "             7.8093e-05, -5.5721e-05,  8.7951e-05, -6.5113e-05,  5.1264e-05,\n",
       "             1.7473e-04,  6.8627e-05, -4.1660e-05,  1.5410e-05, -1.2253e-04,\n",
       "             4.7672e-05,  1.0094e-04, -2.0078e-05, -3.1582e-05,  9.9834e-05,\n",
       "            -8.2580e-06,  4.3446e-05,  4.7678e-05, -1.2760e-04, -3.9587e-05,\n",
       "            -1.8543e-04,  1.8745e-05,  4.3103e-05,  3.5612e-05,  3.8175e-06,\n",
       "             5.7953e-05,  1.2817e-04, -5.5838e-05,  1.4135e-04,  4.9249e-05,\n",
       "             9.9831e-06, -1.3735e-04, -1.2400e-04, -1.5389e-05,  1.5623e-05,\n",
       "             4.4813e-05,  5.9653e-06, -4.5398e-05, -3.6123e-05, -6.2570e-05,\n",
       "            -1.9742e-05,  3.1023e-04,  1.8060e-04,  5.1538e-05, -1.2396e-04,\n",
       "            -1.1035e-04, -3.3287e-05,  6.4876e-05, -6.5607e-05,  5.5405e-05,\n",
       "            -3.5707e-05,  1.6949e-06,  4.2144e-05,  1.3838e-04,  1.0571e-05,\n",
       "            -6.0820e-05,  1.7794e-05, -2.8270e-05, -6.7038e-05, -2.2737e-05,\n",
       "             6.4777e-05, -1.1074e-05, -2.8937e-04,  2.2624e-05, -2.1202e-04,\n",
       "             1.1042e-04]),\n",
       "    'exp_avg_sq': tensor([8.9851e-07, 2.2706e-06, 2.5219e-06, 1.1398e-07, 4.4596e-07, 2.0748e-06,\n",
       "            2.5394e-07, 1.0076e-06, 1.2936e-06, 5.3726e-07, 7.1339e-07, 2.6170e-07,\n",
       "            5.5194e-07, 4.9634e-07, 1.1430e-06, 5.8244e-07, 7.8799e-07, 7.6167e-08,\n",
       "            2.1006e-07, 1.2702e-06, 7.7543e-07, 3.1307e-07, 1.3998e-06, 3.8163e-07,\n",
       "            1.3049e-06, 1.3061e-07, 5.5876e-07, 4.3561e-07, 4.4515e-07, 7.9976e-07,\n",
       "            1.1432e-06, 1.8825e-07, 1.3709e-06, 3.8664e-07, 1.2520e-06, 2.1433e-07,\n",
       "            5.8325e-07, 6.1092e-07, 2.2310e-07, 7.1549e-07, 5.1536e-07, 6.0898e-07,\n",
       "            1.3313e-06, 2.4399e-07, 2.8281e-07, 1.8252e-06, 4.6440e-07, 2.1615e-07,\n",
       "            7.9815e-07, 5.4507e-07, 3.5576e-07, 1.1792e-06, 1.4347e-07, 3.5540e-07,\n",
       "            5.9428e-08, 7.0627e-07, 1.0684e-06, 2.5336e-07, 9.1357e-08, 1.0554e-06,\n",
       "            5.6519e-07, 1.2016e-07, 7.0962e-08, 4.8064e-07, 7.1755e-08, 6.0053e-07,\n",
       "            2.7283e-07, 1.1135e-06, 3.4302e-07, 7.0455e-07, 1.1507e-07, 3.7262e-07,\n",
       "            2.2883e-06, 1.3049e-06, 1.5287e-06, 6.0280e-07, 1.3043e-06, 2.3588e-07,\n",
       "            7.4079e-07, 1.7787e-07, 9.8169e-07, 4.6968e-07, 2.1248e-06, 1.0832e-07,\n",
       "            8.2229e-07, 7.4983e-07, 1.1031e-06, 1.0844e-06, 2.8047e-08, 1.0599e-06,\n",
       "            1.0013e-07, 3.1364e-07, 4.8742e-08, 5.8949e-07, 5.3746e-07, 1.1578e-06,\n",
       "            2.6257e-07, 7.3615e-07, 5.4873e-07, 4.5386e-07, 1.4090e-06, 3.8816e-07,\n",
       "            7.8781e-07, 2.0865e-06, 6.0707e-07, 4.4260e-07, 8.3457e-07, 4.9257e-07,\n",
       "            1.3047e-06, 4.0404e-07, 7.8295e-07, 2.7475e-06, 2.7456e-07, 6.0192e-07,\n",
       "            2.6682e-07, 4.6552e-07, 3.4043e-07, 1.4746e-06, 1.4850e-06, 2.4071e-07,\n",
       "            1.4887e-06, 1.3835e-06, 4.3151e-07, 1.0754e-06, 3.8079e-07, 4.9166e-07,\n",
       "            5.0621e-07, 8.3137e-07, 4.3727e-07, 2.0871e-06, 6.8627e-07, 1.9865e-07,\n",
       "            2.2217e-06, 1.3186e-06, 9.5311e-07, 1.8449e-07, 4.2169e-07, 6.6781e-07,\n",
       "            1.0074e-06, 6.8948e-07, 4.2428e-07, 1.6806e-07, 2.8470e-07, 5.6132e-07,\n",
       "            2.9164e-06, 7.1782e-07, 1.2850e-06, 2.1394e-06, 1.5250e-07, 1.1027e-06,\n",
       "            2.0512e-07, 7.0554e-07, 7.2776e-07, 2.7461e-07, 1.5872e-06, 3.8161e-07,\n",
       "            1.8732e-06, 8.0289e-07, 7.2291e-08, 1.9538e-07, 3.0835e-07, 6.5055e-07,\n",
       "            1.6186e-06, 7.4278e-07, 5.6700e-07, 8.3926e-07, 3.5199e-07, 2.0520e-06,\n",
       "            2.5187e-06, 4.2713e-07, 3.3401e-07, 1.0670e-07, 4.3960e-07, 1.5622e-06,\n",
       "            4.8393e-07, 1.3382e-06, 1.4770e-06, 4.9386e-07, 1.1622e-06, 1.2446e-06,\n",
       "            1.5618e-06, 5.4667e-07, 5.0857e-07, 9.9392e-07, 1.1750e-06, 1.0742e-06,\n",
       "            1.0424e-06, 1.3517e-06, 2.1219e-06, 1.3934e-06, 9.0121e-07, 8.3629e-07,\n",
       "            2.5778e-06, 5.4722e-07, 1.4243e-06, 3.8967e-07, 1.1867e-06, 8.6284e-07,\n",
       "            1.3044e-06, 1.6742e-06, 4.2198e-07, 5.6855e-07, 4.9100e-07, 1.1342e-06,\n",
       "            8.1291e-07, 8.0727e-08, 5.0797e-07, 7.4794e-07, 1.0583e-06, 2.3078e-07,\n",
       "            1.4818e-06, 5.1424e-07, 9.9304e-07, 2.4408e-06, 1.0826e-07, 8.3501e-07,\n",
       "            9.4230e-07, 2.1945e-07, 3.0501e-06, 9.4624e-08, 1.0397e-07, 1.8774e-06,\n",
       "            1.0644e-06, 8.5024e-08, 1.4307e-06, 3.8357e-07, 2.2215e-06, 8.6123e-07,\n",
       "            3.0273e-07, 1.5786e-06, 2.7279e-07, 3.0421e-06, 1.9354e-06, 3.3873e-07,\n",
       "            1.7631e-06, 7.4689e-07, 3.1131e-07, 1.3936e-06, 1.1586e-06, 1.0077e-06,\n",
       "            4.1080e-07, 6.0457e-08, 2.6941e-07, 7.2514e-07, 2.3106e-07, 2.2902e-07,\n",
       "            9.6897e-07, 3.5808e-07, 1.1138e-06, 1.0393e-06, 1.9650e-06, 3.9625e-07,\n",
       "            1.5122e-06, 2.7093e-07, 9.1955e-07, 8.9559e-07])},\n",
       "   6: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[-1.3318e-04, -3.4891e-05,  1.4109e-05,  ...,  1.2408e-05,\n",
       "              5.7053e-05, -3.9018e-05],\n",
       "            [-1.4162e-04, -3.2797e-05, -3.5290e-05,  ...,  9.8583e-05,\n",
       "              1.0428e-04, -8.6371e-05],\n",
       "            [ 7.2178e-06,  2.0425e-05,  7.3287e-06,  ...,  3.6474e-06,\n",
       "             -2.1108e-05,  3.6624e-06],\n",
       "            ...,\n",
       "            [-6.4229e-05, -2.7080e-05, -8.1508e-06,  ...,  6.0189e-05,\n",
       "              6.1387e-05, -2.2039e-05],\n",
       "            [ 3.1415e-04, -2.6364e-04, -6.5260e-05,  ..., -3.3933e-05,\n",
       "              1.3356e-04, -1.5943e-04],\n",
       "            [ 6.6652e-05,  1.4418e-04, -3.9058e-05,  ..., -1.1119e-05,\n",
       "             -1.3547e-04, -3.1854e-06]]),\n",
       "    'exp_avg_sq': tensor([[9.9679e-07, 3.3006e-06, 3.0909e-07,  ..., 4.4564e-07, 9.9165e-07,\n",
       "             1.1840e-06],\n",
       "            [1.7962e-06, 1.6598e-05, 5.7233e-07,  ..., 1.9032e-06, 7.7255e-07,\n",
       "             7.5533e-06],\n",
       "            [8.2159e-08, 1.1317e-07, 1.8295e-08,  ..., 1.7809e-08, 3.8600e-08,\n",
       "             5.4721e-08],\n",
       "            ...,\n",
       "            [5.2152e-07, 4.8339e-06, 1.3243e-07,  ..., 5.5856e-07, 2.2248e-07,\n",
       "             1.9667e-06],\n",
       "            [3.1784e-06, 2.0236e-06, 3.8088e-07,  ..., 2.4769e-07, 8.6524e-07,\n",
       "             1.1189e-06],\n",
       "            [1.4909e-06, 3.5533e-06, 9.1548e-07,  ..., 5.1129e-07, 7.8424e-07,\n",
       "             1.9508e-06]])},\n",
       "   7: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([ 8.1818e-06, -8.9110e-05, -1.4169e-05, -2.1718e-04,  1.5487e-04,\n",
       "             2.2410e-04,  1.7910e-04,  4.5015e-05,  8.2189e-05,  8.9372e-05,\n",
       "            -2.0087e-05,  7.6013e-05,  1.3371e-05, -7.4764e-05,  4.4577e-05,\n",
       "             6.9106e-05,  2.2968e-04, -1.4971e-04, -1.5530e-04,  7.4860e-05,\n",
       "            -6.1286e-05, -1.6081e-04,  2.1031e-04, -1.9214e-04,  1.2672e-04,\n",
       "             1.5721e-04,  1.4643e-04, -3.0033e-05, -1.8075e-04, -2.1292e-05,\n",
       "             1.8277e-04,  5.4553e-05, -1.7232e-05,  4.8346e-05, -1.3654e-04,\n",
       "             1.6042e-04, -1.2175e-04, -1.3285e-05, -2.0233e-05, -1.0856e-04,\n",
       "            -1.6875e-04, -2.2199e-05, -7.0945e-05,  1.5520e-04,  1.5943e-05,\n",
       "            -3.8536e-05,  8.4272e-05, -3.0748e-05, -1.5681e-04,  1.4835e-04,\n",
       "            -1.0611e-05,  9.3547e-05, -9.8145e-05, -1.9690e-06,  2.2386e-04,\n",
       "            -9.3637e-05, -1.0025e-04, -1.7249e-04, -1.8949e-04,  6.4709e-05,\n",
       "             5.5813e-05, -3.4216e-05,  1.6548e-04, -1.4271e-04]),\n",
       "    'exp_avg_sq': tensor([6.3994e-07, 1.7605e-06, 2.8485e-08, 1.0251e-06, 1.6056e-06, 9.8711e-07,\n",
       "            7.3166e-07, 2.9978e-07, 7.5003e-07, 4.8556e-07, 5.4284e-07, 6.8924e-07,\n",
       "            4.2919e-07, 1.2248e-06, 1.3171e-06, 1.1778e-06, 1.0726e-06, 8.0934e-07,\n",
       "            9.7565e-07, 5.4250e-07, 7.7865e-07, 4.6808e-07, 1.2784e-06, 1.2125e-06,\n",
       "            1.1264e-06, 5.5219e-07, 1.4947e-06, 1.7017e-07, 1.5701e-06, 1.6776e-07,\n",
       "            5.6505e-07, 9.6254e-08, 2.6743e-07, 6.0594e-07, 1.2597e-06, 1.1653e-06,\n",
       "            2.9026e-07, 2.8377e-07, 8.5713e-07, 8.2988e-07, 1.4399e-06, 4.2905e-07,\n",
       "            4.2875e-07, 1.4950e-06, 1.6683e-06, 1.8757e-06, 9.6206e-07, 3.4025e-07,\n",
       "            1.5596e-06, 9.8656e-07, 9.7650e-07, 1.5062e-06, 9.2796e-07, 1.3492e-06,\n",
       "            1.2009e-06, 2.8756e-07, 5.0384e-07, 6.4984e-07, 7.1722e-07, 2.0080e-07,\n",
       "            7.9986e-07, 4.6412e-07, 6.8056e-07, 1.1812e-06])},\n",
       "   8: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[ 9.2989e-04, -2.8197e-04,  9.7700e-04,  1.4831e-03,  2.6662e-03,\n",
       "              2.7246e-03,  2.2474e-03,  6.0638e-04,  2.4420e-03, -7.5156e-04,\n",
       "             -2.2884e-03, -5.4509e-04,  2.0598e-03,  2.5569e-03,  1.7553e-03,\n",
       "              4.3590e-04,  2.0557e-03,  4.6832e-04,  2.1869e-03, -8.1923e-04,\n",
       "              1.3433e-03,  3.3664e-03,  2.4047e-04,  2.1446e-03,  8.0979e-04,\n",
       "              1.6277e-03, -4.2967e-04,  1.1280e-03,  1.5870e-03,  4.5434e-04,\n",
       "              2.1562e-03, -1.1925e-03,  1.0775e-03,  3.5560e-04,  3.6890e-04,\n",
       "              4.6554e-04,  2.5580e-03,  4.7026e-04,  5.4725e-04,  1.0632e-03,\n",
       "             -3.5153e-04,  8.6453e-04,  1.1228e-03, -2.4803e-04,  2.6758e-03,\n",
       "              2.3644e-03,  1.7751e-03,  2.1113e-04,  2.1393e-03,  1.2742e-03,\n",
       "              1.1182e-03, -2.7360e-04, -5.0783e-04,  1.3237e-04,  1.9614e-03,\n",
       "              1.1523e-03,  2.0249e-03,  2.7940e-03,  1.3280e-03, -6.4112e-04,\n",
       "             -1.1663e-04, -3.5121e-04,  1.9070e-03,  7.4053e-04],\n",
       "            [ 2.6988e-04,  1.0460e-03, -5.6903e-04, -1.7541e-03, -8.8626e-04,\n",
       "             -1.0192e-03, -1.0268e-03,  2.1051e-04, -9.3083e-04,  5.1527e-04,\n",
       "              1.2757e-03,  4.2879e-04, -8.6749e-04, -8.1981e-04, -5.5458e-04,\n",
       "             -3.3361e-05,  6.5995e-05,  5.3305e-04, -1.3372e-03,  1.4433e-03,\n",
       "             -2.8723e-04, -2.0403e-03,  1.2411e-03, -1.4287e-03,  2.5262e-04,\n",
       "             -8.6271e-04,  1.1947e-03, -1.5580e-04, -1.2497e-03, -6.7962e-04,\n",
       "             -7.5588e-04,  1.6052e-04, -6.2221e-04, -2.7683e-04,  1.1541e-04,\n",
       "              1.7929e-04, -2.0199e-03,  1.5394e-04,  4.1544e-04, -9.3733e-05,\n",
       "              2.3967e-04, -3.5477e-04, -1.0257e-03,  5.7245e-04, -6.6209e-04,\n",
       "             -1.1846e-03, -4.4897e-04,  8.7085e-04, -1.8451e-03, -5.9994e-04,\n",
       "             -5.6173e-04,  1.0129e-03,  1.0669e-03,  7.7229e-04, -1.4167e-03,\n",
       "              1.0269e-04, -3.5267e-04, -2.0920e-03,  5.6757e-05,  1.0449e-03,\n",
       "              4.7992e-04,  7.6986e-04, -4.5107e-04,  3.3160e-04]]),\n",
       "    'exp_avg_sq': tensor([[2.1322e-04, 4.7868e-04, 5.5051e-05, 1.2157e-04, 1.5920e-04, 3.8283e-04,\n",
       "             3.3596e-04, 1.1623e-04, 4.7486e-04, 4.3059e-04, 1.6920e-04, 3.4172e-04,\n",
       "             1.5759e-04, 2.3606e-04, 3.3277e-04, 1.8363e-04, 3.2730e-04, 4.5949e-04,\n",
       "             2.1622e-04, 4.1001e-04, 2.1853e-04, 4.9416e-04, 3.5440e-04, 2.0641e-04,\n",
       "             2.9568e-04, 6.4868e-05, 5.5148e-04, 2.3759e-04, 3.8759e-04, 1.7026e-04,\n",
       "             3.4659e-04, 2.7961e-04, 2.5165e-04, 1.3414e-04, 4.9887e-04, 3.9950e-04,\n",
       "             5.3059e-04, 2.3947e-04, 3.4941e-04, 3.4579e-04, 3.2261e-04, 2.8238e-04,\n",
       "             1.3944e-04, 3.7749e-04, 4.5912e-04, 3.7172e-04, 4.7027e-04, 4.2811e-04,\n",
       "             4.5991e-04, 2.4187e-04, 2.3027e-04, 2.0365e-04, 4.5501e-04, 3.8685e-04,\n",
       "             2.6419e-04, 7.6607e-05, 2.4179e-04, 4.8005e-04, 2.0522e-04, 8.6005e-05,\n",
       "             4.1649e-04, 4.0854e-04, 3.9759e-04, 3.7532e-04],\n",
       "            [5.4488e-04, 4.6272e-04, 2.5918e-05, 1.3166e-04, 2.7288e-04, 2.6933e-04,\n",
       "             2.3862e-04, 3.1753e-04, 3.6928e-04, 2.6640e-04, 1.8991e-04, 3.2247e-04,\n",
       "             4.0269e-04, 6.2390e-04, 5.4940e-04, 4.8015e-04, 1.9061e-04, 2.8544e-04,\n",
       "             3.1103e-04, 2.1236e-04, 3.3814e-04, 2.8157e-04, 2.3673e-04, 3.0678e-04,\n",
       "             5.0730e-04, 7.2056e-05, 2.3796e-04, 4.3964e-04, 2.6957e-04, 4.3060e-04,\n",
       "             1.7862e-04, 1.4676e-04, 2.7710e-04, 1.4980e-04, 2.7157e-04, 3.4658e-04,\n",
       "             3.0136e-04, 4.6738e-04, 3.7340e-04, 5.0962e-04, 1.2877e-04, 3.3046e-04,\n",
       "             2.7784e-04, 2.4417e-04, 5.9116e-04, 4.0650e-04, 3.5811e-04, 2.7468e-04,\n",
       "             2.4021e-04, 4.0326e-04, 4.6843e-04, 2.4050e-04, 2.1793e-04, 4.3613e-04,\n",
       "             2.0065e-04, 1.1314e-04, 5.6559e-04, 3.6955e-04, 1.8520e-04, 1.6775e-04,\n",
       "             4.5095e-04, 5.1597e-04, 1.3851e-04, 4.1827e-04]])},\n",
       "   9: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([ 0.0017, -0.0006]),\n",
       "    'exp_avg_sq': tensor([6.3247e-05, 5.0524e-05])},\n",
       "   10: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[-3.7451e-05, -1.2777e-04, -3.8084e-05,  ..., -3.5120e-05,\n",
       "             -8.7263e-05,  4.2691e-05],\n",
       "            [-3.7702e-06,  1.4136e-04,  1.8230e-05,  ..., -4.5192e-06,\n",
       "              9.9508e-05,  1.5095e-05],\n",
       "            [-8.0312e-05,  1.6088e-05, -4.7529e-06,  ...,  1.9253e-05,\n",
       "              1.4826e-05,  3.6356e-06],\n",
       "            ...,\n",
       "            [-2.9223e-05,  1.2446e-04,  5.7331e-05,  ...,  4.6363e-05,\n",
       "             -2.1789e-05,  1.9811e-04],\n",
       "            [ 5.1164e-05,  8.7992e-05, -1.7892e-05,  ...,  7.4770e-05,\n",
       "              5.0965e-05,  2.9347e-05],\n",
       "            [-2.9767e-05,  2.2679e-05,  3.1062e-05,  ..., -3.3066e-06,\n",
       "              3.3106e-05, -1.2480e-04]]),\n",
       "    'exp_avg_sq': tensor([[6.2770e-06, 8.3291e-06, 2.4622e-06,  ..., 1.3318e-06, 2.1770e-06,\n",
       "             6.8336e-06],\n",
       "            [4.4048e-06, 9.8697e-06, 1.4127e-06,  ..., 1.0712e-06, 1.2178e-06,\n",
       "             6.1589e-06],\n",
       "            [1.5822e-06, 2.7761e-06, 1.0027e-06,  ..., 6.6963e-07, 5.5051e-07,\n",
       "             1.8534e-06],\n",
       "            ...,\n",
       "            [1.2117e-05, 1.2126e-05, 2.9839e-06,  ..., 2.6133e-06, 5.2998e-06,\n",
       "             6.6727e-06],\n",
       "            [2.2569e-06, 1.7718e-06, 4.9788e-07,  ..., 4.8859e-07, 7.7729e-07,\n",
       "             1.2644e-06],\n",
       "            [2.5453e-06, 3.8795e-06, 7.9992e-07,  ..., 4.3546e-07, 7.6874e-07,\n",
       "             2.7951e-06]])},\n",
       "   11: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([-1.0960e-04,  7.3560e-05,  2.1893e-05,  1.0880e-04, -3.1444e-05,\n",
       "             3.4024e-06, -3.3264e-05, -1.4778e-04,  1.9618e-06, -3.3482e-05,\n",
       "            -4.3897e-05, -2.9703e-05, -1.0746e-04,  1.0120e-04, -9.4307e-05,\n",
       "             3.0064e-05,  3.3393e-05,  9.2003e-05,  3.3321e-05, -1.7168e-05,\n",
       "            -5.5515e-05,  4.7492e-05,  2.8415e-05,  3.9691e-05,  2.7031e-05,\n",
       "            -3.5855e-05,  1.2555e-04, -4.1073e-06, -3.4177e-05,  2.4065e-05,\n",
       "            -3.5405e-05,  9.3057e-05, -1.1887e-05,  7.4445e-05,  5.3630e-05,\n",
       "            -8.8982e-05,  4.1782e-05,  9.5541e-05,  3.1201e-05,  1.3739e-05,\n",
       "             6.1034e-06, -3.3487e-05,  1.9368e-05,  1.9663e-04, -5.6997e-05,\n",
       "            -2.8686e-05, -8.2869e-05,  2.6924e-05, -5.6231e-06, -1.4264e-04,\n",
       "             9.6183e-08,  1.1287e-06, -1.4263e-05, -9.5880e-05, -1.6167e-04,\n",
       "             4.4710e-05, -3.3382e-05, -4.7926e-05,  3.4478e-05, -1.1245e-05,\n",
       "            -4.2517e-05,  6.7871e-05, -8.8112e-06,  1.3077e-04]),\n",
       "    'exp_avg_sq': tensor([2.2999e-06, 1.6917e-06, 1.2064e-06, 2.8393e-06, 2.0697e-06, 5.9642e-07,\n",
       "            1.2456e-06, 4.3299e-06, 1.2402e-06, 3.6953e-07, 2.2235e-06, 6.1842e-06,\n",
       "            3.3080e-06, 1.8670e-06, 1.1522e-06, 1.1424e-06, 1.9124e-06, 1.9608e-06,\n",
       "            4.0493e-07, 2.7052e-06, 1.7103e-06, 2.0734e-06, 1.1957e-06, 3.2373e-06,\n",
       "            3.6150e-07, 6.7319e-07, 1.3239e-06, 1.3550e-07, 2.0068e-06, 1.5051e-06,\n",
       "            5.2561e-06, 1.6431e-06, 1.0827e-06, 2.7151e-06, 1.5773e-06, 3.7498e-06,\n",
       "            2.7492e-06, 1.9571e-06, 1.1088e-06, 6.4593e-07, 8.2175e-08, 2.5776e-06,\n",
       "            1.1051e-06, 4.4529e-06, 1.3362e-06, 1.2902e-06, 2.4826e-06, 7.1916e-07,\n",
       "            1.3675e-07, 3.2556e-06, 3.9123e-10, 1.5145e-06, 8.2275e-08, 2.7566e-06,\n",
       "            5.7066e-06, 3.9071e-06, 1.2295e-06, 1.4196e-06, 2.0021e-06, 1.6886e-06,\n",
       "            5.3649e-07, 3.3167e-06, 6.0798e-07, 1.0806e-06])},\n",
       "   12: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([[ 6.9294e-04, -9.4752e-04, -2.6951e-03,  3.8611e-04,  2.7662e-04,\n",
       "              1.1712e-03, -7.9097e-04, -2.4628e-03,  2.6855e-03,  2.7667e-04,\n",
       "              7.7140e-04, -1.7614e-04, -2.6716e-03,  7.4951e-04,  3.8303e-03,\n",
       "             -9.1189e-04,  3.3309e-04, -1.6984e-03, -1.6887e-03,  1.8148e-03,\n",
       "              3.6541e-03,  7.2270e-04,  1.2034e-03, -2.2349e-04, -9.4012e-04,\n",
       "             -1.2271e-04, -1.6646e-03,  2.8490e-05,  2.7134e-03,  2.7000e-03,\n",
       "             -1.5153e-03,  5.5108e-04,  6.7999e-04, -1.6706e-03,  1.3838e-03,\n",
       "             -5.8170e-04, -9.8009e-04, -2.6810e-04,  2.6566e-04, -2.2391e-04,\n",
       "              1.0939e-04,  1.7945e-04,  4.9954e-04, -1.5126e-03, -3.5032e-03,\n",
       "              2.2791e-05,  6.2856e-04, -1.5258e-03, -1.5124e-03, -2.2719e-03,\n",
       "              3.4764e-05,  1.3596e-03, -2.0971e-03, -1.3107e-03, -7.9984e-04,\n",
       "              2.8543e-03, -5.6736e-04, -1.0688e-03, -1.2453e-03,  1.5440e-03,\n",
       "             -8.2871e-04,  4.3528e-04, -3.0613e-04, -4.1894e-04],\n",
       "            [-4.8302e-03, -1.7251e-03,  3.1009e-03,  3.8563e-03,  2.2886e-03,\n",
       "             -1.8225e-03,  2.2184e-03,  2.2053e-03, -1.3703e-03,  4.1907e-03,\n",
       "              1.7832e-03, -2.2167e-03,  2.3198e-03,  3.4871e-03,  9.7408e-04,\n",
       "              2.4071e-03, -2.9112e-03, -1.9692e-03,  1.4600e-03, -2.3465e-03,\n",
       "             -1.9340e-03,  2.6946e-03,  1.2663e-03,  1.3098e-03, -4.9588e-04,\n",
       "              3.0743e-03, -2.7130e-03, -5.6510e-04,  2.4983e-04, -1.4424e-03,\n",
       "              1.5726e-04, -2.5099e-03, -4.1204e-05,  2.4014e-03, -1.6450e-03,\n",
       "              2.4288e-03, -9.9397e-04,  2.9546e-03, -2.0544e-03, -4.4557e-04,\n",
       "              2.5057e-03, -1.1466e-03, -1.9017e-03,  1.3697e-03,  7.2195e-04,\n",
       "             -5.0580e-03,  4.1056e-03,  2.7130e-03,  2.3530e-04,  2.3234e-03,\n",
       "              9.4652e-05, -2.4539e-03, -3.8463e-03, -6.0442e-04,  2.5813e-03,\n",
       "             -2.8057e-03, -1.9808e-03,  1.9658e-03,  3.6163e-05, -2.2966e-03,\n",
       "              1.0986e-03, -2.8561e-03,  5.8872e-05, -2.1264e-03]]),\n",
       "    'exp_avg_sq': tensor([[9.7452e-04, 1.9604e-04, 8.0295e-04, 6.5584e-04, 3.0494e-04, 2.0949e-04,\n",
       "             3.5463e-04, 1.0460e-03, 1.0907e-03, 3.7583e-04, 4.7231e-04, 1.0249e-03,\n",
       "             8.6617e-04, 5.9784e-04, 6.6004e-04, 6.3039e-04, 8.2796e-04, 3.7307e-04,\n",
       "             5.6955e-04, 5.1903e-04, 1.0118e-03, 7.4754e-04, 7.0497e-04, 5.9796e-04,\n",
       "             8.7054e-05, 1.7784e-04, 4.1174e-04, 9.5647e-05, 3.3811e-04, 2.6296e-04,\n",
       "             5.9859e-04, 2.7088e-04, 5.3083e-04, 6.1838e-04, 2.4501e-04, 3.9580e-04,\n",
       "             8.0093e-04, 7.2538e-04, 3.3165e-04, 6.3953e-04, 3.1407e-04, 4.0292e-04,\n",
       "             2.7158e-04, 2.5433e-03, 7.9360e-04, 9.2958e-04, 5.1060e-04, 1.0332e-03,\n",
       "             5.2524e-04, 8.4093e-04, 3.8532e-06, 6.0010e-04, 4.9441e-04, 9.1140e-04,\n",
       "             2.2275e-03, 8.7585e-04, 6.3174e-04, 6.7750e-04, 6.0348e-04, 9.5527e-04,\n",
       "             7.2001e-04, 4.5874e-04, 3.7694e-04, 5.1216e-04],\n",
       "            [1.0966e-03, 1.6710e-04, 6.4187e-04, 9.5891e-04, 3.7768e-04, 1.8707e-04,\n",
       "             4.6046e-04, 9.0053e-04, 7.2126e-04, 6.2942e-04, 3.6884e-04, 1.2661e-03,\n",
       "             5.7469e-04, 9.3605e-04, 4.5105e-04, 5.5692e-04, 5.2212e-04, 4.2218e-04,\n",
       "             3.9990e-04, 5.4338e-04, 6.5246e-04, 8.5697e-04, 4.8710e-04, 6.4189e-04,\n",
       "             7.4175e-05, 1.8971e-04, 5.6512e-04, 9.2734e-05, 4.6600e-04, 2.2998e-04,\n",
       "             6.0415e-04, 2.8108e-04, 3.6939e-04, 5.8183e-04, 2.6784e-04, 5.5802e-04,\n",
       "             1.0650e-03, 1.0253e-03, 5.1318e-04, 5.5366e-04, 4.6196e-04, 5.4283e-04,\n",
       "             3.8288e-04, 2.2488e-03, 5.6164e-04, 1.4939e-03, 8.9085e-04, 1.0064e-03,\n",
       "             4.6005e-04, 7.4730e-04, 3.8197e-06, 8.3066e-04, 7.6081e-04, 7.8033e-04,\n",
       "             2.2502e-03, 8.4180e-04, 8.2808e-04, 7.6334e-04, 8.6987e-04, 6.4237e-04,\n",
       "             7.3373e-04, 6.2775e-04, 5.8889e-04, 5.5332e-04]])},\n",
       "   13: {'step': tensor(3780.),\n",
       "    'exp_avg': tensor([-3.3255e-04,  9.5730e-05]),\n",
       "    'exp_avg_sq': tensor([0.0002, 0.0002])}},\n",
       "  'param_groups': [{'lr': 0.001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}]},\n",
       " 'args': {'devices': '0',\n",
       "  'batch_size': 256,\n",
       "  'use_bipartite_graphs': False,\n",
       "  'epochs': 200,\n",
       "  'lr': 0.001,\n",
       "  'num_workers': 0,\n",
       "  'seed': 42,\n",
       "  'primal_weight': 0.1,\n",
       "  'dual_weight': 0.1,\n",
       "  'stationarity_weight': 0.6,\n",
       "  'complementary_slackness_weight': 0.2,\n",
       "  'max_lr': 0.001,\n",
       "  'log_every': 5,\n",
       "  'problems': ['RND'],\n",
       "  'is_sizes': [2],\n",
       "  'ca_sizes': [2],\n",
       "  'sc_sizes': [2],\n",
       "  'cfl_sizes': [5],\n",
       "  'rnd_sizes': [2],\n",
       "  'data_root': './data/instances'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68871b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KKTNetMLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=256, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): SELU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): SELU()\n",
       "  )\n",
       "  (head_x): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (head_lam): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GNNPolicy(args) if use_bipartite_graphs else KKTNetMLP(m,n)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06324310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=pad_collate_graphs\n",
    "            if use_bipartite_graphs\n",
    "            else make_pad_collate(M_fixed=m, N_fixed=n),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8ccf75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original problem has 2 variables (0 bin, 0 int, 0 impl, 2 cont) and 2 constraints\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    input = batch[0]\n",
    "    if use_bipartite_graphs:\n",
    "        x_hat, lam_hat = model(\n",
    "        input.constraint_features,\n",
    "        input.edge_index,\n",
    "        input.edge_attr,\n",
    "        input.variable_features,\n",
    "    )\n",
    "    else:\n",
    "        \n",
    "        pred = model(input)\n",
    "        if args.use_bipartite_graphs:\n",
    "            x_hat, lam_hat = pred\n",
    "        else:\n",
    "            x_hat = pred[0][:n]\n",
    "            lam_hat = pred[0][n:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3172d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_bipartite_graphs:\n",
    "    solution_path = args.file_path.replace(\"BG\",\"solution\").replace(\".bg\",\".sol\")\n",
    "else:\n",
    "    solution_path = args.file_path.replace(\"instance\",\"solution\") + \".sol\"\n",
    "    solution_path = solution_path.replace(\"solutions\", \"instances\")\n",
    "\n",
    "with open(solution_path, \"rb\") as file:\n",
    "    solution_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43325411",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = solution_data[\"sols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c6a51ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aa94e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x_hat |    optimal |       Diff\n",
      "-----------------------------------\n",
      "   -0.2738 |    -0.5322 |     0.2584\n",
      "    0.6501 |     0.9742 |     0.3241\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'x_hat':>10} | {'optimal':>10} | {'Diff':>10}\")\n",
    "print(\"-\" * 35)\n",
    "for t, f in zip(x_hat, solutions[0]):\n",
    "    print(f\"{t.item():10.4f} | {f:10.4f} | {abs(t.item() - f):10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e7c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
